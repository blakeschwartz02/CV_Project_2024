{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill these file paths with the locations on your machine. \n",
    "PATH_TO_CODE = 'C:/Users/blake/OneDrive/Desktop/Computer Vision/Project/pastis-benchmark/code' # path to the code folder of the repo\n",
    "PATH_TO_PASTIS = 'D:/PASTIS'\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(PATH_TO_CODE)\n",
    "\n",
    "# import the necessary packages\n",
    "from torch.nn import ConvTranspose2d\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import Module\n",
    "from torch.nn import ModuleList\n",
    "from torch.nn import ReLU\n",
    "from torchvision.transforms import CenterCrop\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchnet as tnt\n",
    "\n",
    "from torchmetrics import JaccardIndex\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle as pkl\n",
    "import time\n",
    "\n",
    "cm = matplotlib.colormaps.get_cmap('tab20')\n",
    "def_colors = cm.colors\n",
    "cus_colors = ['k'] + [def_colors[i] for i in range(1,20)]+['w']\n",
    "cmap = ListedColormap(colors = cus_colors, name='agri',N=21)\n",
    "\n",
    "def get_rgb(x, batch_index=0, t_show=1):\n",
    "    \"\"\"Utility function to get a displayable rgb image \n",
    "    from a Sentinel-2 time series.\n",
    "    \"\"\"\n",
    "    im = x['S2'][batch_index, t_show, [2,1,0]].cuda().numpy()\n",
    "    mx = im.max(axis=(1,2))\n",
    "    mi = im.min(axis=(1,2))   \n",
    "    im = (im - mi[:,None,None])/(mx - mi)[:,None,None]\n",
    "    im = im.swapaxes(0,2).swapaxes(0,1)\n",
    "    im = np.clip(im, a_max=1, a_min=0)\n",
    "    return im\n",
    "\n",
    "def get_radar(x, batch_index=0, t_show=6, orbit='D'):\n",
    "    \"\"\"Utility function to get a displayable image \n",
    "    from a Sentinel-1 time series.\n",
    "    \"\"\"\n",
    "    im = x['S1{}'.format(orbit)][batch_index, t_show].cuda().numpy()\n",
    "    mx = im.max(axis=(1,2))\n",
    "    mi = im.min(axis=(1,2))   \n",
    "    im = (im - mi[:,None,None])/(mx - mi)[:,None,None]\n",
    "    im = im.swapaxes(0,2).swapaxes(0,1)\n",
    "    im = np.clip(im, a_max=1, a_min=0)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading patch metadata . . .\n",
      "Done.\n",
      "Dataset ready.\n"
     ]
    }
   ],
   "source": [
    "from dataloader import PASTIS_Dataset\n",
    "from collate import pad_collate\n",
    "\n",
    "dt = PASTIS_Dataset(PATH_TO_PASTIS, norm=True, target='semantic')\n",
    "# If you only need to evaluate semantic segmentation use target='semantic'\n",
    "\n",
    "dl = torch.utils.data.DataLoader(dt, batch_size=100, collate_fn=pad_collate, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(input_image, input_mask):\n",
    "   if tf.random.uniform(()) > 0.5:\n",
    "       # Random flipping of the image and mask\n",
    "       input_image = tf.image.flip_left_right(input_image)\n",
    "       input_mask = tf.image.flip_left_right(input_mask)\n",
    "\n",
    "   return input_image, input_mask\n",
    "\n",
    "def normalize(input_image, input_mask):\n",
    "   input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "   input_mask -= 1\n",
    "   return input_image, input_mask\n",
    "\n",
    "def load_image_train(x, y):\n",
    "   input_image = x\n",
    "   input_mask = y\n",
    "   input_image, input_mask = augment(input_image, input_mask)\n",
    "   input_image, input_mask = normalize(input_image, input_mask)\n",
    "   return input_image, input_mask\n",
    "\n",
    "def load_image_test(x, y):\n",
    "   input_image = x\n",
    "   input_mask = y\n",
    "   input_image, input_mask = normalize(input_image, input_mask)\n",
    "   return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_todevice(x, device):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.to(device)\n",
    "    elif isinstance(x, dict):\n",
    "        return {k: recursive_todevice(v, device) for k, v in x.items()}\n",
    "    else:\n",
    "        return [recursive_todevice(c, device) for c in x]\n",
    "\n",
    "\n",
    "def prepare_output():\n",
    "    os.makedirs('output', exist_ok=True)\n",
    "    for fold in range(1, 6):\n",
    "        os.makedirs(os.path.join(\"Fold_{}\".format(fold)), exist_ok=True)\n",
    "\n",
    "\n",
    "def checkpoint(fold, log):\n",
    "    with open(\n",
    "        os.path.join('output', \"Fold_{}\".format(fold), \"trainlog.json\"), \"w\"\n",
    "    ) as outfile:\n",
    "        json.dump(log, outfile, indent=4)\n",
    "\n",
    "\n",
    "def save_results(fold, metrics):\n",
    "    if isinstance(metrics, torch.Tensor):\n",
    "        metrics = metrics.cpu().numpy()\n",
    "    with open(\n",
    "        os.path.join('output', \"Fold_{}\".format(fold), \"test_metrics.json\"), \"w\"\n",
    "    ) as outfile:\n",
    "        json.dump(metrics, outfile, indent=4)\n",
    "    \n",
    "def iterate(\n",
    "    model, data_loader, criterion, optimizer=None, mode=\"train\", device=None\n",
    "):\n",
    "    loss_meter = tnt.meter.AverageValueMeter()\n",
    "    IoU = JaccardIndex(task='multiclass', num_classes=20).to(device)\n",
    "    t_start = time.time()\n",
    "\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        if device is not None:\n",
    "            batch = recursive_todevice(batch, device)\n",
    "        (x, dates), y = batch\n",
    "        y = y.long()\n",
    "        x = x['S2'][:, 0, range(0,3), :, :].to(device)\n",
    "\n",
    "        if mode != \"train\":\n",
    "            with torch.no_grad():\n",
    "                out = model(x)\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "\n",
    "        loss = criterion(out, y)\n",
    "        if mode == \"train\":\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = out.argmax(dim=1)\n",
    "            pred = pred.resize(30, 128, 128)\n",
    "\n",
    "        loss_meter.add(loss.item())\n",
    "\n",
    "        if (i + 1) % 5 == 0:\n",
    "            acc = IoU(pred, y)\n",
    "            print(\n",
    "                \"Step [{}/{}], Loss: {:.4f}, mIoU {:.2f}\".format(\n",
    "                    i + 1, len(data_loader), loss_meter.value()[0], acc\n",
    "                )\n",
    "            )\n",
    "\n",
    "    t_end = time.time()\n",
    "    total_time = t_end - t_start\n",
    "    print(\"Epoch time : {:.1f}s\".format(total_time))\n",
    "    metrics = {\n",
    "        \"{}_loss\".format(mode): loss_meter.value()[0],\n",
    "        \"{}_IoU\".format(mode): acc.item(),\n",
    "        \"{}_epoch_time\".format(mode): total_time,\n",
    "    }\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(Module):\n",
    "\tdef __init__(self, inChannels, outChannels):\n",
    "\t\tsuper().__init__()\n",
    "\t\t# store the convolution and RELU layers\n",
    "\t\tself.conv1 = Conv2d(inChannels, outChannels, 3)\n",
    "\t\tself.relu = ReLU()\n",
    "\t\tself.conv2 = Conv2d(outChannels, outChannels, 3)\n",
    "\tdef forward(self, x):\n",
    "\t\t# apply CONV => RELU => CONV block to the inputs and return it\n",
    "\t\treturn self.conv2(self.relu(self.conv1(x)))\n",
    "\t\n",
    "class Encoder(Module):\n",
    "\tdef __init__(self, channels=(3, 16, 32, 64)):\n",
    "\t\tsuper().__init__()\n",
    "\t\t# store the encoder blocks and maxpooling layer\n",
    "\t\tself.encBlocks = ModuleList(\n",
    "\t\t\t[Block(channels[i], channels[i + 1])\n",
    "\t\t\t \tfor i in range(len(channels) - 1)])\n",
    "\t\tself.pool = MaxPool2d(2)\n",
    "\t\t\n",
    "\tdef forward(self, x):\n",
    "\t\t# initialize an empty list to store the intermediate outputs\n",
    "\t\tblockOutputs = []\n",
    "\t\t# loop through the encoder blocks\n",
    "\t\tfor block in self.encBlocks:\n",
    "\t\t\t# pass the inputs through the current encoder block, store\n",
    "\t\t\t# the outputs, and then apply maxpooling on the output\n",
    "\t\t\tx = block(x)\n",
    "\t\t\tblockOutputs.append(x)\n",
    "\t\t\tx = self.pool(x)\n",
    "\t\t# return the list containing the intermediate outputs\n",
    "\t\treturn blockOutputs\n",
    "\t\n",
    "class Decoder(Module):\n",
    "\tdef __init__(self, channels=(64, 32, 16)):\n",
    "\t\tsuper().__init__()\n",
    "\t\t# initialize the number of channels, upsampler blocks, and\n",
    "\t\t# decoder blocks\n",
    "\t\tself.channels = channels\n",
    "\t\tself.upconvs = ModuleList(\n",
    "\t\t\t[ConvTranspose2d(channels[i], channels[i + 1], 2, 2)\n",
    "\t\t\t \tfor i in range(len(channels) - 1)])\n",
    "\t\tself.dec_blocks = ModuleList(\n",
    "\t\t\t[Block(channels[i], channels[i + 1])\n",
    "\t\t\t \tfor i in range(len(channels) - 1)])\n",
    "\tdef forward(self, x, encFeatures):\n",
    "\t\t# loop through the number of channels\n",
    "\t\tfor i in range(len(self.channels) - 1):\n",
    "\t\t\t# pass the inputs through the upsampler blocks\n",
    "\t\t\tx = self.upconvs[i](x)\n",
    "\t\t\t# crop the current features from the encoder blocks,\n",
    "\t\t\t# concatenate them with the current upsampled features,\n",
    "\t\t\t# and pass the concatenated output through the current\n",
    "\t\t\t# decoder block\n",
    "\t\t\tencFeat = self.crop(encFeatures[i], x)\n",
    "\t\t\tx = torch.cat([x, encFeat], dim=1)\n",
    "\t\t\tx = self.dec_blocks[i](x)\n",
    "\t\t# return the final decoder output\n",
    "\t\treturn x\n",
    "\tdef crop(self, encFeatures, x):\n",
    "\t\t# grab the dimensions of the inputs, and crop the encoder\n",
    "\t\t# features to match the dimensions\n",
    "\t\t(_, _, H, W) = x.shape\n",
    "\t\tencFeatures = CenterCrop([H, W])(encFeatures)\n",
    "\t\t# return the cropped features\n",
    "\t\treturn encFeatures\n",
    "\t\n",
    "class UNet(Module):\n",
    "\tdef __init__(self, encChannels=(3, 16, 32, 64),\n",
    "\t\t decChannels=(64, 32, 16),\n",
    "\t\t nbClasses=20, retainDim=True,\n",
    "\t\t outSize=(128,  128)):\n",
    "\t\tsuper().__init__()\n",
    "\t\t# initialize the encoder and decoder\n",
    "\t\tself.encoder = Encoder(encChannels)\n",
    "\t\tself.decoder = Decoder(decChannels)\n",
    "\t\t# initialize the regression head and store the class variables\n",
    "\t\tself.head = Conv2d(decChannels[-1], nbClasses, 1)\n",
    "\t\tself.retainDim = retainDim\n",
    "\t\tself.outSize = outSize\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# grab the features from the encoder\n",
    "\t\tencFeatures = self.encoder(x)\n",
    "\t\t# pass the encoder features through decoder making sure that\n",
    "\t\t# their dimensions are suited for concatenation\n",
    "\t\tdecFeatures = self.decoder(encFeatures[::-1][0],\n",
    "\t\t\tencFeatures[::-1][1:])\n",
    "\t\t# pass the decoder features through the regression head to\n",
    "\t\t# obtain the segmentation mask\n",
    "\t\tmap = self.head(decFeatures)\n",
    "\t\t# check to see if we are retaining the original output\n",
    "\t\t# dimensions and if so, then resize the output to match them\n",
    "\t\tif self.retainDim:\n",
    "\t\t\tmap = F.interpolate(map, self.outSize)\n",
    "\t\t# return the segmentation map\n",
    "\t\treturn map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet().to('cuda:0')\n",
    "# initialize loss function and optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# initialize a dictionary to store training history\n",
    "H = {\"train_loss\": [], \"test_loss\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading patch metadata . . .\n",
      "Done.\n",
      "Dataset ready.\n",
      "Reading patch metadata . . .\n",
      "Done.\n",
      "Dataset ready.\n",
      "Reading patch metadata . . .\n",
      "Done.\n",
      "Dataset ready.\n",
      "Train 1455, Val 482, Test 496\n",
      "EPOCH 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\blake\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:775: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [5/48], Loss: 2.7710, mIoU 0.02\n",
      "Step [10/48], Loss: 2.6057, mIoU 0.02\n",
      "Step [15/48], Loss: 2.4490, mIoU 0.02\n",
      "Step [20/48], Loss: 2.3572, mIoU 0.02\n",
      "Step [25/48], Loss: 2.2963, mIoU 0.02\n",
      "Step [30/48], Loss: 2.2400, mIoU 0.02\n",
      "Step [35/48], Loss: 2.2142, mIoU 0.02\n",
      "Step [40/48], Loss: 2.2013, mIoU 0.02\n",
      "Step [45/48], Loss: 2.1838, mIoU 0.02\n",
      "Epoch time : 579.8s\n",
      "EPOCH 2/20\n",
      "Step [5/48], Loss: 2.0107, mIoU 0.02\n",
      "Step [10/48], Loss: 1.9957, mIoU 0.02\n",
      "Step [15/48], Loss: 1.9977, mIoU 0.02\n",
      "Step [20/48], Loss: 2.0247, mIoU 0.02\n",
      "Step [25/48], Loss: 2.0145, mIoU 0.02\n",
      "Step [30/48], Loss: 2.0005, mIoU 0.02\n",
      "Step [35/48], Loss: 2.0047, mIoU 0.02\n",
      "Step [40/48], Loss: 2.0073, mIoU 0.02\n",
      "Step [45/48], Loss: 2.0159, mIoU 0.02\n",
      "Epoch time : 504.0s\n",
      "EPOCH 3/20\n",
      "Step [5/48], Loss: 2.0403, mIoU 0.02\n",
      "Step [10/48], Loss: 1.9913, mIoU 0.02\n",
      "Step [15/48], Loss: 1.9924, mIoU 0.02\n",
      "Step [20/48], Loss: 2.0029, mIoU 0.02\n",
      "Step [25/48], Loss: 2.0066, mIoU 0.02\n",
      "Step [30/48], Loss: 2.0159, mIoU 0.02\n",
      "Step [35/48], Loss: 2.0093, mIoU 0.02\n",
      "Step [40/48], Loss: 2.0068, mIoU 0.02\n",
      "Step [45/48], Loss: 2.0121, mIoU 0.02\n",
      "Epoch time : 469.5s\n",
      "EPOCH 4/20\n",
      "Step [5/48], Loss: 1.9920, mIoU 0.02\n",
      "Step [10/48], Loss: 2.0210, mIoU 0.02\n",
      "Step [15/48], Loss: 2.0262, mIoU 0.02\n"
     ]
    }
   ],
   "source": [
    "fold_sequence = [\n",
    "    [[1, 2, 3], [4], [5]],\n",
    "    [[2, 3, 4], [5], [1]],\n",
    "    [[3, 4, 5], [1], [2]],\n",
    "    [[4, 5, 1], [2], [3]],\n",
    "    [[5, 1, 2], [3], [4]],\n",
    "]\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "prepare_output()\n",
    "device = torch.device('cuda:0')\n",
    "batch_size = 30\n",
    "\n",
    "for fold, (train_folds, val_fold, test_fold) in enumerate(fold_sequence):\n",
    "    # Dataset definition\n",
    "    dt_args = dict(\n",
    "        folder='D:/PASTIS',\n",
    "        norm=True,\n",
    "        target=\"semantic\",\n",
    "        sats=[\"S2\"],\n",
    "    )\n",
    "\n",
    "    dt_train = PASTIS_Dataset(**dt_args, folds=train_folds)\n",
    "    dt_val = PASTIS_Dataset(**dt_args, folds=val_fold)\n",
    "    dt_test = PASTIS_Dataset(**dt_args, folds=test_fold)\n",
    "\n",
    "    collate_fn = pad_collate\n",
    "    train_loader = data.DataLoader(\n",
    "        dt_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    val_loader = data.DataLoader(\n",
    "        dt_val,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    test_loader = data.DataLoader(\n",
    "        dt_test,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"Train {}, Val {}, Test {}\".format(len(dt_train), len(dt_val), len(dt_test))\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    trainlog = {}\n",
    "    best_mIoU = 0\n",
    "\n",
    "    weights = torch.ones(20, device=device).float()\n",
    "    criterion = CrossEntropyLoss(weight=weights)\n",
    "\n",
    "    for epoch in range(1, 21):\n",
    "        print(\"EPOCH {}/{}\".format(epoch, 20))\n",
    "\n",
    "        train_metrics = iterate(\n",
    "            model,\n",
    "            data_loader=train_loader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            mode=\"train\",\n",
    "            device=device,\n",
    "        )\n",
    "        if epoch % 4 == 0 and epoch > 3:\n",
    "            print(\"Validation . . . \")\n",
    "            model.eval()\n",
    "            val_metrics = iterate(\n",
    "                model,\n",
    "                data_loader=val_loader,\n",
    "                criterion=criterion,\n",
    "                optimizer=optimizer,\n",
    "                mode=\"val\",\n",
    "                device=device,\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                \"Loss {:.4f}, IoU {:.4f}\".format(\n",
    "                    val_metrics[\"val_loss\"],\n",
    "                    val_metrics[\"val_IoU\"],\n",
    "                )\n",
    "            )\n",
    "\n",
    "            trainlog[epoch] = {**train_metrics, **val_metrics}\n",
    "            checkpoint(fold + 1, trainlog)\n",
    "            if val_metrics[\"val_IoU\"] >= best_mIoU:\n",
    "                best_mIoU = val_metrics[\"val_IoU\"]\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"epoch\": epoch,\n",
    "                        \"state_dict\": model.state_dict(),\n",
    "                        \"optimizer\": optimizer.state_dict(),\n",
    "                    },\n",
    "                    os.path.join(\n",
    "                        'output', \"Fold_{}\".format(fold + 1), \"model.pth.tar\"\n",
    "                    ),\n",
    "                )\n",
    "        else:\n",
    "            trainlog[epoch] = {**train_metrics}\n",
    "            checkpoint(fold + 1, trainlog)\n",
    "\n",
    "    print(\"Testing best epoch . . .\")\n",
    "    model.load_state_dict(\n",
    "        torch.load(\n",
    "            os.path.join(\n",
    "                'output', \"Fold_{}\".format(fold + 1), \"model.pth.tar\"\n",
    "            )\n",
    "        )[\"state_dict\"]\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    test_metrics = iterate(\n",
    "        model,\n",
    "        data_loader=test_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        mode=\"test\",\n",
    "        device=device,\n",
    "    )\n",
    "    print(\n",
    "        \"Loss {:.4f},  IoU {:.4f}\".format(\n",
    "            test_metrics[\"test_loss\"],\n",
    "            test_metrics[\"test_IoU\"]\n",
    "        )\n",
    "    )\n",
    "    save_results(fold + 1, test_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
